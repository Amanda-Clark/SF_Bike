{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "station= pd.read_csv('../input/station.csv')\n",
    "status= pd.read_csv('../input/status.csv')\n",
    "trip= pd.read_csv('../input/trip.csv')\n",
    "weather= pd.read_csv('../input/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip.duration = trip.duration/60\n",
    "trip = trip[trip.duration <= 360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trip.start_date = pd.to_datetime(trip.start_date, format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip['date'] = pd.to_datetime(trip.start_date)\n",
    "trip.date=trip.date.dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trip['station_date'] = trip['date'].map(str) + \" \"+trip['start_station_name']\n",
    "cols = list(trip)\n",
    "cols.insert(0, cols.pop(cols.index('station_date')))\n",
    "trip = trip.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each entry in the date feature is a trip. \n",
    "#By finding the total number of times a date is listed, we know how many trips were taken on that date.\n",
    "station_dates = {}\n",
    "for d in trip.station_date:\n",
    "    if d not in station_dates:\n",
    "        station_dates[d] = 1\n",
    "    else:\n",
    "        station_dates[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the data frame that will be used for training, with the dictionary we just created.\n",
    "df2 = pd.DataFrame.from_dict(station_dates, orient = \"index\")\n",
    "df2['station_date'] = df2.index\n",
    "df2['trips'] = df2.ix[:,0]\n",
    "train = df2.ix[:,1:3]\n",
    "train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip = pd.merge(trip, station, left_on='start_station_id', right_on='id')\n",
    "trip['in_city'] = np.where(trip['lat'] >37.5630, 1, 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip['zip_to_use'] = np.where(trip['lat'] >37.5630, 95113, 94107 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(train, trip, left_on='station_date', right_on='station_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge1.drop_duplicates(subset='station_date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(weather[weather.zip_code == 94063].index, inplace=True)\n",
    "weather.drop(weather[weather.zip_code == 94301].index, inplace=True)\n",
    "weather.drop(weather[weather.zip_code == 94041].index, inplace=True)\n",
    "weather = weather.drop(['max_gust_speed_mph'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.get_dummies(weather.events)\n",
    "weather = weather.merge(events, left_index = True, right_index = True)\n",
    "weather = weather.drop(['events'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this feature from a string to numeric.\n",
    "#Use errors = 'coerce' because some values currently equal 'T' and we want them to become NAs.\n",
    "weather.precipitation_inches = pd.to_numeric(weather.precipitation_inches, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.loc[weather.precipitation_inches.isnull(), \n",
    "            'precipitation_inches'] = weather[weather.precipitation_inches.notnull()].precipitation_inches.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "merge2['merge_key'] = merge2['zip_to_use'].map(str) + \" \"+merge2['date'].map(str)\n",
    "weather['merge_key'] = weather['zip_code'].map(str) + \" \"+weather['date'].map(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "merge2['merge_key'] = weather['merge_key'].str.strip()\n",
    "merge3 = pd.merge(merge2, weather,   left_on=['merge_key'], right_on = ['merge_key' ], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3.drop(['id_x','duration', 'start_date', 'start_station_name', 'start_station_id', 'end_date','end_station_name', \n",
    "             'end_station_id'],1, inplace= True)\n",
    "merge3.drop(['id_y','name', 'lat', 'long', 'city','installation_date', 'zip_to_use', 'merge_key'],1, inplace= True)\n",
    "merge3.drop(['bike_id','zip_code_y'],1, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Find all of the holidays during our time span\n",
    "calendar = USFederalHolidayCalendar()\n",
    "holidays = calendar.holidays(start=merge3.date_x.min(), end=merge3.date_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all of the business days in our time span\n",
    "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "business_days = pd.DatetimeIndex(start=merge3.date_x.min(), end=merge3.date_x.max(), freq=us_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_days = pd.to_datetime(business_days, format='%Y/%m/%d').date\n",
    "holidays = pd.to_datetime(holidays, format='%Y/%m/%d').date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A 'business_day' or 'holiday' is a date within either of the respected lists.\n",
    "\n",
    "merge3['business_day'] = merge3.date_x.isin(business_days)\n",
    "merge3['holiday'] = merge3.date_x.isin(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert True to 1 and False to 0\n",
    "merge3.business_day = merge3.business_day.map(lambda x: 1 if x == True else 0)\n",
    "merge3.holiday = merge3.holiday.map(lambda x: 1 if x == True else 0)\n",
    "merge3.subscription_type = merge3.subscription_type.map(lambda x: 1 if x == 'Subscriber'else 0)\n",
    "merge3.drop(['station_date', 'date_x', 'date_y'], 1, inplace=True)\n",
    "merge3.drop(['zip_code_x'], 1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = merge3.trips\n",
    "merge4 = merge3.drop(['trips'], 1)\n",
    "my_imputer = SimpleImputer()\n",
    "merge4 = my_imputer.fit_transform(merge3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, y_train, y_test = train_test_split(merge4, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "'max_depth': [4, 6],\n",
    "'min_samples_leaf': [3, 5, 9, 17],\n",
    "\n",
    "}\n",
    "est = GradientBoostingRegressor(n_estimators=500, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gs_cv = GridSearchCV(est, param_grid, n_jobs=4).fit(train_set, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999827911283387"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.score(test_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gs = GradientBoostingRegressor(learning_rate=.1, max_depth=6, min_samples_leaf=3, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gs.fit(train_set, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999827910710617"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gs.score(test_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
